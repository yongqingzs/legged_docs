# HistoryWrapper 类分析

本文档旨在深入分析 `walk-these-ways` 项目中 `go1_gym_deploy/envs/history_wrapper.py` 文件中的 `HistoryWrapper` 类，阐述其工作原理、功能及各成员函数的实现。

## 1. HistoryWrapper 类整体功能概述

`HistoryWrapper` 类是一个环境包装器（Wrapper），用于为强化学习环境添加观测历史记录功能。它在原始环境的基础上维护一个观测历史缓冲区，将过去多个时间步的观测拼接成一个扩展的观测向量，提供给策略网络使用。这对于需要时序信息的任务（如动态步态控制）至关重要，能够帮助策略学习时间依赖关系。类的核心功能包括：

- **历史缓冲区管理**：初始化并维护一个固定长度的观测历史张量。
- **观测扩展**：在每次观测时，将当前观测添加到历史缓冲区，并移除最旧的观测。
- **接口兼容**：包装原始环境的方法，确保与强化学习框架无缝集成。
- **重置处理**：在环境重置时清空历史缓冲区，避免历史污染。

该类适用于需要历史上下文的强化学习任务，通过扩展观测空间来捕捉时间序列信息。

## 2. 各成员函数的详细功能

### 2.1. 构造函数 `__init__(self, env)`
- **功能**：初始化 `HistoryWrapper` 实例，设置历史缓冲区。
- **参数**：`env`：要包装的原始环境实例。
- **操作**：
  - 从环境配置中获取历史长度（`num_observation_history`）。
  - 计算历史观测的总维度（`num_obs_history = obs_history_length * num_obs`）。
  - 初始化历史缓冲区张量（全零，形状为 `(num_envs, num_obs_history)`，设备与环境一致）。

### 2.2. `step(self, action)`
- **功能**：执行一步环境交互，并更新观测历史。
- **参数**：`action`：要执行的动作。
- **操作**：
  - 调用原始环境的 `step` 方法获取观测、奖励、完成标志和信息。
  - 更新历史缓冲区：移除最旧的观测，添加当前观测。
  - 返回扩展的观测字典（包含当前观测、特权观测和历史观测）。

### 2.3. `get_observations(self)`
- **功能**：获取当前观测，并更新历史缓冲区。
- **操作**：
  - 调用原始环境的 `get_observations` 方法。
  - 更新历史缓冲区。
  - 返回扩展的观测字典。

### 2.4. `get_obs(self)`
- **功能**：获取当前观测（兼容不同环境接口），并更新历史缓冲区。
- **操作**：
  - 调用原始环境的 `get_obs` 方法。
  - 更新历史缓冲区。
  - 返回扩展的观测字典。

### 2.5. `reset_idx(self, env_ids)`
- **功能**：重置特定环境的索引和历史。
- **参数**：`env_ids`：要重置的环境 ID 列表。
- **操作**：
  - 调用原始环境的 `reset_idx` 方法。
  - 将指定环境的观测历史清零。

### 2.6. `reset(self)`
- **功能**：重置所有环境和历史缓冲区。
- **操作**：
  - 调用原始环境的 `reset` 方法。
  - 获取特权观测。
  - 将所有环境的观测历史清零。
  - 返回扩展的重置观测字典。

### 2.7. `__getattr__(self, name)`
- **功能**：代理属性访问到内部环境。
- **参数**：`name`：属性名。
- **操作**：返回原始环境的相应属性，实现透明包装。

## 3. 补充说明

- **历史更新机制**：使用 `torch.cat` 拼接张量，实现滑动窗口式的历史维护，确保最新观测始终在缓冲区末尾。
- **内存效率**：历史缓冲区在 GPU 上分配（如果环境支持），利用 PyTorch 的张量操作加速。
- **兼容性**：支持多种环境接口（`get_observations` 和 `get_obs`），适用于不同版本的仿真框架。
- **重置策略**：在重置时清空历史，避免跨 episode 的信息泄露。
- **扩展观测**：返回字典格式，便于策略网络区分当前观测和历史上下文。

这份文档全面地分析了 `HistoryWrapper` 类的架构和技术细节。
